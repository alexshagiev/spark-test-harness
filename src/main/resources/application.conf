conf {
    spark {
        appname = "test-harness"
    }
    hdfs {
        # local host
        default-fs = "hdfs://localhost:9000"
        # aws emr
        # url = "hdfs://ip-172-31-14-179.us-east-2.compute.internal:8020"
        base-dir = /user/test-harness
        l0-dir = ${conf.hdfs.base-dir}/data/l0
        l1-dir = ${conf.hdfs.base-dir}/data/l1
    }
}

scenarios {
    # run = {jsonl : [ R100xC100, R1000xC100]}
    run = {jsonl : [R100xC100, R1000000xC100, R1000000xC1000]}
    jsonl {
        l0-dir = ${conf.hdfs.l0-dir}/jsonl
        l1-dir = ${conf.hdfs.l1-dir}/jsonl
        R100xC100 {
            rows = 100
            columns = 100
            # determines if every row will be unique or same values will be repeated across several rows
            rows_uniqueness_factor = 1
            name = R100xC100.jsonl
        }
        R1000000xC100 {
            rows = 1000000
            columns = 100
            rows_uniqueness_factor = 1000000/10000
            name = R1000000xC100.jsonl
        }
        R1000000xC1000 {
            rows = 1000000
            columns = 1000
            rows_uniqueness_factor = 1000000/100
            name = R1000000xC1000.jsonl
        }
    }

}